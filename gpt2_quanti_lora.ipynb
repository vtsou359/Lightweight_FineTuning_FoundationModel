{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fine-Tuning Quantised GPT-2 (4bit) using Lora\n",
    "\n",
    "### PEFT Method:\n",
    "The project implements the PEFT (Parameter-Efficient Fine-Tuning) method to fine-tune a Quantised GPT-2 model using LoRA (Low-Rank Adaptation) for sequence classification tasks.\n",
    "\n",
    "### Model:\n",
    "The model used is the GPT-2 model (Quantised), which is a transformer-based language model pretrained on a large corpus of text data.\n",
    "\n",
    "### Evaluation Approach:\n",
    "The evaluation approach involves computing evaluation metrics like accuracy, precision, recall, and F1 score on the foundation and fine-tuned Quantised GPT-2 model for the given sequence classification task. Then both models are compared.\n",
    "\n",
    "### Fine-Tuning Dataset:\n",
    "The dataset used for fine-tuning the model contains consumer complaints of National Bank of America with corresponding labels for classification (Mortgage, Credit/Prepaid Cards). The dataset is preprocessed, tokenized, and split into training and testing sets for fine-tuning the model."
   ],
   "id": "ab1b51ff62410a34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Imports",
   "id": "808c669ff0af2b0c"
  },
  {
   "cell_type": "code",
   "id": "3afc9c71868e81e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:57:53.061673Z",
     "start_time": "2025-01-29T19:57:28.197166Z"
    }
   },
   "source": [
    "from datasets import load_dataset, ClassLabel\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                          DataCollatorWithPadding,\n",
    "                          Trainer,\n",
    "                          TrainingArguments,\n",
    "                          BitsAndBytesConfig\n",
    ")\n",
    "from peft import (LoraConfig,\n",
    "                  TaskType,\n",
    "                  PeftModel,\n",
    "                  get_peft_model,\n",
    "                  prepare_model_for_kbit_training,\n",
    "                  )\n",
    "from sklearn.metrics import (\n",
    "\taccuracy_score,\n",
    "\tprecision_score,\n",
    "\trecall_score,\n",
    "\tf1_score,\n",
    "\tconfusion_matrix,\n",
    "\tConfusionMatrixDisplay\n",
    ")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#model name id in hugging face\n",
    "mdl_tok_name = \"gpt2\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Test Nvidia CUDA in torch",
   "id": "a3852959fe21ee20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:57:53.202983Z",
     "start_time": "2025-01-29T19:57:53.078684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing required function\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "\tprint(torch.cuda.is_available())\n",
    "\tprint(torch.cuda.device_count())\n",
    "\tprint(torch.cuda.get_device_name(0))\n",
    "\ttorch.cuda.empty_cache()\n",
    "\ttorch.device('cuda')\n",
    "else:\n",
    "\tprint(\"CUDA is not available on this system. Please ensure that a CUDA-capable device is properly configured.\")\n"
   ],
   "id": "32b559eb5a5b08f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 4070 Ti\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Defining Evaluation Metrics as a function",
   "id": "cf120beb5d67c4be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:57:53.628890Z",
     "start_time": "2025-01-29T19:57:53.622062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "\t\"\"\"\n",
    "\tCompute evaluation metrics from the given predictions and labels.\n",
    "\n",
    "\tThis function accepts an evaluation prediction object containing prediction\n",
    "\tscores and true labels, calculates the relevant classification metrics, and\n",
    "\treturns a dictionary containing these metrics. Metrics computed include\n",
    "\taccuracy, precision, recall, and F1 score.\n",
    "\n",
    "\t:param eval_pred: A tuple containing the predictions and true labels. The\n",
    "\t    predictions are expected as a 2D array where each row contains the\n",
    "\t    probabilistic scores for each class, and true labels are expected as\n",
    "\t    a 1D array of ground truth class indices.\n",
    "\t:return: A dictionary containing the evaluation metrics, with the following\n",
    "\t    keys: \"accuracy\", \"precision\", \"recall\", and \"f1\".\n",
    "\t:rtype: dict\n",
    "\t\"\"\"\n",
    "\t# Unpack predictions and labels\n",
    "\tpredictions, labels = eval_pred\n",
    "\t# Get the predicted class (argmax selects the class with the highest score)\n",
    "\tpredictions = np.argmax(predictions, axis = 1)\n",
    "\t# Compute metrics\n",
    "\taccuracy = accuracy_score(y_true = labels, y_pred = predictions)\n",
    "\tprecision = precision_score(y_true =labels, y_pred =predictions)\n",
    "\trecall = recall_score(y_true = labels, y_pred = predictions)\n",
    "\tf1 = f1_score(y_true = labels, y_pred = predictions)\n",
    "\t# Return all metrics\n",
    "\treturn {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ],
   "id": "70c1a899c9f1b258",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating a confusion matrix visualisation function",
   "id": "419966502e852532"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:57:53.646414Z",
     "start_time": "2025-01-29T19:57:53.639643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_confusion_matrix(data, cl_classes, trainer_ ,title_text = 'Confusion Matrix - Validation Set'):\n",
    " \"\"\"\n",
    "\t    Constructs and displays a confusion matrix to evaluate the performance of\n",
    "\t    a classifier on a given dataset, highlighting the relationship between true\n",
    "\t    labels and predicted classifications. The confusion matrix provides insights\n",
    "\t    into label-wise classification accuracy and errors.\n",
    "\n",
    "\t    :param data: A dataset containing the validation data and their corresponding\n",
    "\t        labels in a structure suitable for evaluation.\n",
    "\t    :type data: Any\n",
    "\t    :param cl_classes: A list of possible classification labels (classes) corresponding\n",
    "\t        to the data. Each item in the list represents a unique label of the classification\n",
    "\t        task.\n",
    "\t    :type cl_classes: list\n",
    "\t    :param trainer_: An object or function used to generate predictions for the given\n",
    "\t        dataset. It must support the required interface or methods to provide predictions\n",
    "\t        or probabilities for the data.\n",
    "\t    :type trainer_: Any\n",
    "\t    :param title_text: A title for the confusion matrix visualization, used to label\n",
    "\t        the plot for clarity. Defaults to 'Confusion Matrix - Validation Set'.\n",
    "\t    :type title_text: str\n",
    "\t    :return: The generated confusion matrix after the evaluation of the data for\n",
    "\t        comparison with true labels. The matrix format assigns rows to true labels\n",
    "\t        and columns to predicted labels.\n",
    "\t    :rtype: Any\n",
    " \"\"\"\n",
    " results = trainer_.predict(data)\n",
    " # Create confusion matrix\n",
    " y_true = results.label_ids\n",
    " y_pred = results.predictions.argmax(axis=1)\n",
    " cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    " # Display the confusion matrix\n",
    " disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=cl_classes)\n",
    " disp.plot(cmap=plt.cm.Blues)\n",
    " plt.title(title_text, pad= 12)\n",
    " plt.show()\n",
    " return None"
   ],
   "id": "9e8135c656772a18",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loading the filtered dataset",
   "id": "d044bb1571cbc875"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-29T19:57:54.477951Z",
     "start_time": "2025-01-29T19:57:53.706469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the file path to the dataset\n",
    "file_path = Path(\"data/filtered_dataset.csv\")\n",
    "\n",
    "# Load the dataset using Hugging Face's `load_dataset`\n",
    "dataset = load_dataset('csv', data_files = str(file_path))\n",
    "\n",
    "# Inspect the unique values in the 'labels' column\n",
    "product_classes = dataset[\"train\"].unique(\"Product\")\n",
    "\n",
    "# Convert the 'Product' column to a ClassLabel feature\n",
    "product_label = ClassLabel(names=product_classes)\n",
    "dataset = dataset.cast_column(\"Product\", product_label)\n",
    "\n",
    "# Rename the columns: \"Product\" to \"labels\", and \"Consumer complaint narrative\" to \"complaint\"\n",
    "dataset = dataset.rename_column(\"Product\", \"labels\")\n",
    "dataset = dataset.rename_column(\"Consumer complaint narrative\", \"complaint\")\n",
    "\n",
    "# Extract the features (columns) we want\n",
    "dataset = \\\n",
    "    dataset[\"train\"].select_columns(\n",
    "        [\"complaint\", \"labels\"]\n",
    "    ).train_test_split(\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        seed=23,\n",
    "        stratify_by_column=\"labels\"\n",
    "    )\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "# View the resulting dataset\n",
    "print(dataset)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['complaint', 'labels'],\n",
      "        num_rows: 1600\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['complaint', 'labels'],\n",
      "        num_rows: 400\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Inspecting the labels\n",
    "\n",
    "Credit card or Prepaid Card is labeled as 0 and  Mortgage is labeled as 1"
   ],
   "id": "5515a2b1ef507acb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:57:54.510269Z",
     "start_time": "2025-01-29T19:57:54.501799Z"
    }
   },
   "cell_type": "code",
   "source": "product_label",
   "id": "b9040be5e710a56f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['Mortgage', 'Credit card or prepaid card'], id=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Preprocess dataset\n",
    "\n",
    "Tokenizing 'Consumer complaint narrative' feature values"
   ],
   "id": "d33a3db87bf72169"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:59:15.195009Z",
     "start_time": "2025-01-29T19:57:54.564965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(mdl_tok_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Let's use a lambda function to tokenize all the examples\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"complaint\"],\n",
    "                            truncation=True,\n",
    "                            padding=True,\n",
    "                            return_tensors = \"pt\"\n",
    "                            ),\n",
    "\t    batched=True,\n",
    "\n",
    "    )\n",
    "\n",
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ],
   "id": "4de95d07c818cebd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['complaint', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1600\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Quantisation configuration",
   "id": "cd0e9bf3047d3e57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:59:15.264257Z",
     "start_time": "2025-01-29T19:59:15.258068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define 4-bit configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "\tload_in_4bit = True,  # Enabling 4-bit quantization\n",
    "\tbnb_4bit_use_double_quant = True,  # Using double quantization for better accuracy\n",
    "\tbnb_4bit_quant_type = \"nf4\",  # Using NormalFloat4 for higher precision (than fp4)\n",
    "\tbnb_4bit_compute_dtype = torch.bfloat16\n",
    ")\n"
   ],
   "id": "be74bfb3368cbbf6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loading Model with quantisation configuration",
   "id": "7edce09ded4bded4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:59:20.948693Z",
     "start_time": "2025-01-29T19:59:15.402514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_4b = AutoModelForSequenceClassification.from_pretrained(\n",
    "    mdl_tok_name,\n",
    "    num_labels = 2,\n",
    "    id2label = {0: \"Mortgage\", 1: \"Credit card or prepaid card\"},\n",
    "    label2id = {\"Credit card or prepaid card\": 1, \"Mortgage\": 0},\n",
    "\tdevice_map = \"auto\", # Automatically move to GPU\n",
    "\tquantization_config = bnb_config,  # Passing the bitsandbytes config\n",
    "\ttorch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "# Update the model config with the pad token ID\n",
    "model_4b.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Saving the model\n",
    "model_4b.save_pretrained(\"./vtsoumpris/fnc-gpt2-q4\")\n",
    "\n",
    "print(model_4b)"
   ],
   "id": "382a8fe8d3b4e8d0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Linear4bit(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
      "          (c_proj): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Preparing model for kbit training",
   "id": "267eb06a7d297988"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:59:20.977298Z",
     "start_time": "2025-01-29T19:59:20.970706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_4b.gradient_checkpointing_enable()\n",
    "model_4b = prepare_model_for_kbit_training(model_4b)"
   ],
   "id": "e48fe4c42816d0f6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Lora Configuration for gpt-2 model\n",
   "id": "780a69ac1b88f5a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:59:21.016583Z",
     "start_time": "2025-01-29T19:59:21.011685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config = \\\n",
    "\tLoraConfig(\n",
    "\t\tr = 6,  # Low-rank dimension\n",
    "\t\ttarget_modules = [\"c_attn\", \"c_proj\", \"c_fc\"],\n",
    "\t\ttask_type = TaskType.SEQ_CLS,  # Task type: Sequence Classification\n",
    "\t\tlora_alpha = 32,  # Scaling factor: 32, should consider to increase for larger models\n",
    "\t\tlora_dropout = 0.1,  # Dropout, increase slightly if facing overfitting,\n",
    "\t\tbias = \"none\"\n",
    "\t)"
   ],
   "id": "8fdfeb02484293c4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loading foundation model as PEFT model (with Lora adapter)",
   "id": "5ab5a28f57985e24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:59:21.118914Z",
     "start_time": "2025-01-29T19:59:21.040366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "peft_model = get_peft_model(model_4b, lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ],
   "id": "92bbb4de048aa7a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 886,272 || all params: 125,327,616 || trainable%: 0.7072\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Define Trainer to fine-tune the foundation model\n",
    "\n",
    "The HuggingFace Trainer class handles the training and eval loop for PyTorch.\n",
    "\n",
    "You can find more at this [link](https://huggingface.co/docs/transformers/main_classes/trainer)."
   ],
   "id": "fb730de6ffb08b74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T19:59:21.313Z",
     "start_time": "2025-01-29T19:59:21.128931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model= peft_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir= \"./data/creditc_mortg\",\n",
    "        # Learning rate\n",
    "        learning_rate= 2e-5,\n",
    "        # Train/Validate batch size\n",
    "        per_device_train_batch_size= 8, # 8: Batch size to avoid memory crashes\n",
    "        per_device_eval_batch_size= 8, # 8: Same for evaluation\n",
    "        # Evaluate and save the model after each epoch\n",
    "        eval_strategy= \"epoch\", # Evaluate at the end of each epoch\n",
    "        save_strategy= \"epoch\", # Save model checkpoint every epoch\n",
    "\t    # Epochs and weight decay\n",
    "        num_train_epochs= 10,\n",
    "        weight_decay= 0.01,  # Standard weight decay\n",
    "\t    # Resource management\n",
    "\t\tgradient_accumulation_steps= 4,  # Simulate larger batches with accumulation\n",
    "\t    #\n",
    "        load_best_model_at_end= True,\n",
    "\t    use_cpu= False, # Ensure GPU usage\n",
    "\t    seed = 42,\n",
    "\t    data_seed = 42,\n",
    "\t    # Enable logging for losses\n",
    "\t    logging_dir= \".data/logs/gpt2_q4_lora_logs\", #dir to save logs\n",
    "        logging_strategy = \"epoch\", #log at regular intervals\n",
    "\t    log_level = 'error'\n",
    "    ),\n",
    "    train_dataset= tokenized_dataset[\"train\"],\n",
    "    eval_dataset= tokenized_dataset[\"test\"],\n",
    "    tokenizer= tokenizer,\n",
    "    data_collator= DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics= compute_metrics,\n",
    ")"
   ],
   "id": "92839e841ad89c62",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vtsoumpris\\AppData\\Local\\Temp\\ipykernel_12560\\2970903001.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Start fine-tuning",
   "id": "57b08c612fd471de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T22:16:19.979401Z",
     "start_time": "2025-01-27T21:48:52.563165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "# Suppress all UserWarnings\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "\n",
    "trainer.train()"
   ],
   "id": "e3182054a5155275",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 27:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.275300</td>\n",
       "      <td>0.766183</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.807700</td>\n",
       "      <td>0.695666</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.552764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.728600</td>\n",
       "      <td>0.662285</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.621762</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.610687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.678700</td>\n",
       "      <td>0.628544</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.618785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.628600</td>\n",
       "      <td>0.578574</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.556100</td>\n",
       "      <td>0.525877</td>\n",
       "      <td>0.752500</td>\n",
       "      <td>0.791908</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.734584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.475596</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.856287</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.779292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.417600</td>\n",
       "      <td>0.408745</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.857923</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.819843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.383000</td>\n",
       "      <td>0.380845</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.888268</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.839050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.368166</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.893855</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.844327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.6324154472351075, metrics={'train_runtime': 1647.2146, 'train_samples_per_second': 9.713, 'train_steps_per_second': 0.304, 'total_flos': 8448620101632000.0, 'train_loss': 0.6324154472351075, 'epoch': 10.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Final fine-tuned model evaluation metrics",
   "id": "316e5a584b9b71a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T22:16:31.145370Z",
     "start_time": "2025-01-27T22:16:20.033491Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate()",
   "id": "39e8497ae9c42335",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3681662678718567,\n",
       " 'eval_accuracy': 0.8525,\n",
       " 'eval_precision': 0.8938547486033519,\n",
       " 'eval_recall': 0.8,\n",
       " 'eval_f1': 0.8443271767810027,\n",
       " 'eval_runtime': 11.099,\n",
       " 'eval_samples_per_second': 36.039,\n",
       " 'eval_steps_per_second': 4.505,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Saving the model for later use",
   "id": "2c266b74491ac154"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T22:16:31.535188Z",
     "start_time": "2025-01-27T22:16:31.178378Z"
    }
   },
   "cell_type": "code",
   "source": "peft_model.save_pretrained(\"./vtsoumpris/fnc-gpt2-q4lora\")",
   "id": "d2900e98d50d4751",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Printing some of the predictions and the real labels",
   "id": "3101e08f0c8bfd6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T22:17:29.351278Z",
     "start_time": "2025-01-27T22:17:28.700953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make a dataframe with the predictions and the text and the labels\n",
    "items_for_manual_review = tokenized_dataset[\"test\"].select(\n",
    "    [0, 1, 22, 31, 43, 199, 150, 40]\n",
    ")\n",
    "\n",
    "results = trainer.predict(items_for_manual_review)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"complaint\": [item[\"complaint\"] for item in items_for_manual_review],\n",
    "        \"predictions\": results.predictions.argmax(axis=1),\n",
    "        \"labels\": results.label_ids,\n",
    "    }\n",
    ")\n",
    "# Show all the cell\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df"
   ],
   "id": "909478a8b3b51301",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       complaint  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          I was offered a secured line of credit with Bank of America. I was asked to pay a deposit of {$200.00}, was told that after a few months, usually 6 months of good payment history, I would get an increase on my credit limit, and that after 12 months, I would get my deposit back. Neither of these promises took place, instead, Bank of America closed my credit line without any previous notice and has never returned my {$200.00} deposit and my payment history is/was excellent. The line of credit has been closed for a few months now and I have yet to received my {$200.00} deposit.   \n",
       "1  Bank of America started servicing my Mortgage in XXXX. I had a conventional loan. I received a permanent home modification in XXXX. My loan has always been in good standing and was never deliquent. I modified the loan to get a lower interest rate. Apparently Bank of America made some mistakes during this process of the modification and I had to do the Modification over again. In XXXX Bank of Americaa sold my loan to a Dept Collection Agency named XXXX. This company has unscrupolus business practices that has caused emotional and financial harm to me. In XXXX, XXXX, I began to make my contractual mortgage payments to XXXX as my new servicer in the amount of {$620.00}. XXXX immediately claimed I missed a payment to Bank of Americia on XXXX XXXX and begin to harrass me on my cell phone demanding that I pay them. I told them I had never missed a payment with Bank of America and why would they concern themselfs with my Morgage with Bank of America 2 year prior to them taking over my loan? XXXX claimed they paid Bank of America the missing funds on XXXX XXXX, XXXX and begin to charge me late fees and evenutlly cause my loan to go into Foreclosure. XXXX also increased my Mortgage amount from {$620.00} to {$790.00} stating I had a shortage in Escorws without properly notifying me of the large increase. When I paid the amount I was contracted to pay, XXXX put my mortgage payment in a suspense account stating they do not take partial payments. XXXX begain to add late fees, unauthorized inspection fees and demanded full payment and threatend to start legal procedures of foreclosure. I contacted XXXX representatives in XXXX week trying to resolve this proplem. XXXX did XXXX escrow analysis from XXXX XXXX to XXXX, XXXX and each time my escow shortage changed with each representative. I contacted Bank of America and aske them if they have any knowledge of a missed payment and they said no. I asked Bank of America to fax over my payment history which they did and there was no record of a missed payment. XXXX continued to harrass me as a collection agency does. I was confused about how my mortgage having been serviced by a professional and reputable company such as Bank of America could go from excellent payment history to Foreclosure in a matter of 4 months. I was so distraught I reached out to my brother for support that perhaps I was somehow making a mistake. He looked at my banking records from XXXX XXXX Bank and Bank of America 's record and he too found no missing payments and he wrote the CEO of the Company and filed a complaint that XXXX was falsesifying records to delibertly cause my loan to be in default, however, XXXX 's investigation found no errors and reported my loan deliquent to the credit bureau and I was disqulified from receiving my {$5000.00} inscentive payment for keeping my loan in good standing. After much grief dealing with a Criminal company, I reached out to the XXXX office to file a complaint against XXXX and discovered XXXX is not a bank at all they are a fly by night collection company. Bank of America has no documentation of XXXX ever sending them funds on XXXX XXXX and there is no missing payment. XXXX is running scams on their customers and there is plenty documentatiion as such. My loan should have never went to a collection agency and XXXX uses off shore agents to handle mortgages and unauthorized escrow agents who are not trained and who has made many mistakes on my account. In XXXX, XXXX blessed me to receive the hardest hit fund in the amount of {$20000.00} to be applied to the principal balance but Nationstar didnt apply the funds until XXXX, XXXX. I had made several extra payments to my principal balance but XXXX refused to apply these funds as I alocated .Why was my loan turned over to collection   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  I was told I could not get modification ok.so I was read on XXXX XXXX XXXX web hardest hit funds programs and XXXX XXXX XXXX home equity assistance or and repayment plans of up to 12 months to help catch up on a past due payments and I was not told about this forbearance I can do that all so I did not no they had all these programs I only no about the modification program I found this on XXXX XXXX XXXX web I do n't need my payment to be reduce i can pay that and all so and extra {$500.00} a month to caught up I 'm out of work because I was XXXX by a lady and she was very XXXX and that why I 'm out of work these last four year I ben having not such good luck first I had XXXX XXXX and I beat that thank to XXXX and now XXXX XXXX XXXX XXXX and both of my XXXX XXXX XXXX XXXX XXXX XXXX XXXX and I have XXXX XXXX XXXX XXXX I did not ask for this. all I 'm ask for to be able to pay a full note and {$500.00} extra thank u   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Date : XX/XX/2021 Amount : {$4500.00} I tried calling the issuer of the XXXX  Unemployment Card ( Bank of America XXXX about why they get my unemployment card closed which they have no positive responds. I tried sending out my unemployment money in the unemployment card to an authorized third party and the Bank of America got my card closed. After several callings and provision of all required information they still can not uplift the lock on my card.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 I have started refinance process with Bank of America in XX/XX/2017 whereas the sales agent promised me best rates and smooth process. As part of the process, they told me that they will carry out appraisal of my house and I need to pay upfront for it. I was not shared the amount that I need to pay for appraisal and was told that I will be refunded at the end when appraisal closes. I agreed to it as I didn't expect any issues in my loan process. During appraisal, an incorrect report came out which talks about an issue that I don't have in my home. I tried to explain to bank and appraisal company but they are not ready to correct the report resulting in my mortgage process going on hold. Bank has charged me for my appraisal fees but they didn't worked with appraisal company to correct the report even after I provided the reason for incorrectness of the report. My home ( in exactly same condition ) has gone through 3-4 appraisals before this appraisal but never such issue happened. I can provide more specifics when asked. \\n\\nI have also reached out to XXXX, CA to help me with issue in appraisal report.   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  I have been working with XXXX for the past two years to get a home loan with Bank of America. My closing was schedule for XX/XX/XXXX. On XX/XX/XXXX my file to updated and showed, \" XXXX pending compliance and verbal verification of employment. '' Two days later, underwriting was suspended and additional conditions was placed on my file. All additional information was provided and closing was then extended to XX/XX/XXXX. My XXXX counselor and closing attorney has tried with no success since XX/XX/XXXX to contact someone in the underwriting department of BOA and no one is responding. I have already wired my closing funds to the attorney. Due to the explainable delay, I was forced to give up my apartment and place my belongings in storage.My son and I am now living in car just to achieve the American Dream. I have XXXX and my health is being seriously impacted by this as well. Moving my stuff to the storage unit cost me {$820.00}, which means I will be charged another {$820.00} to move my stuff from there. I was told by another agent that works with XXXX that she has clients that were cleared to closed since XX/XX/2019 and Bank of America still has no sent the paperwork to the closing attorney. \\nI would really hope that Bank of America is not intentionally stall the XXXX loans. I just want to close on this house and get on with my life. I am afraid that the seller might terminate the contact and walk away with my earnest money. PLEASE HELP ME!!!!!   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       This is a \" qualified written request '' under Sec tion 6 of  the Real Estate Settlement Procedures Act ( RESPA ).     I am writing you today as I disagree with the past due payments you are reporting on my credit reports. They do not line up with my records and I believe that my payments  may have  been misapplied. The particular lates referred to are : Late Payments Being Reported : 60 days past due as of  XXXX   XXXX  30 days past due as of  XXXX   XXXX ,  XXXX   XXXX ,  XXXX   XXXX ,  XXXX   XXXX ,  XXXX   XXXX   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              I am working with Bank of America on a home loan. The closing is scheduled for today ie XXXX XXXX, 2015. But even after repeated requests I was not provided the closing disclosure documents. They just sent it to me and its not what we had discussed initially. They pushed out my closing several times stating they had not received some documents from the closing attorney etc. I dont understand how they can be so lax in their approach. Why cant they track progress and raise a red flag if something is not happening on time..This has caused tremendous discomfort and heartache to my family and me. Pls help..   \n",
       "\n",
       "   predictions  labels  \n",
       "0            1       1  \n",
       "1            0       0  \n",
       "2            0       0  \n",
       "3            1       1  \n",
       "4            0       0  \n",
       "5            0       0  \n",
       "6            0       0  \n",
       "7            0       0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint</th>\n",
       "      <th>predictions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was offered a secured line of credit with Bank of America. I was asked to pay a deposit of {$200.00}, was told that after a few months, usually 6 months of good payment history, I would get an increase on my credit limit, and that after 12 months, I would get my deposit back. Neither of these promises took place, instead, Bank of America closed my credit line without any previous notice and has never returned my {$200.00} deposit and my payment history is/was excellent. The line of credit has been closed for a few months now and I have yet to received my {$200.00} deposit.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bank of America started servicing my Mortgage in XXXX. I had a conventional loan. I received a permanent home modification in XXXX. My loan has always been in good standing and was never deliquent. I modified the loan to get a lower interest rate. Apparently Bank of America made some mistakes during this process of the modification and I had to do the Modification over again. In XXXX Bank of Americaa sold my loan to a Dept Collection Agency named XXXX. This company has unscrupolus business practices that has caused emotional and financial harm to me. In XXXX, XXXX, I began to make my contractual mortgage payments to XXXX as my new servicer in the amount of {$620.00}. XXXX immediately claimed I missed a payment to Bank of Americia on XXXX XXXX and begin to harrass me on my cell phone demanding that I pay them. I told them I had never missed a payment with Bank of America and why would they concern themselfs with my Morgage with Bank of America 2 year prior to them taking over my loan? XXXX claimed they paid Bank of America the missing funds on XXXX XXXX, XXXX and begin to charge me late fees and evenutlly cause my loan to go into Foreclosure. XXXX also increased my Mortgage amount from {$620.00} to {$790.00} stating I had a shortage in Escorws without properly notifying me of the large increase. When I paid the amount I was contracted to pay, XXXX put my mortgage payment in a suspense account stating they do not take partial payments. XXXX begain to add late fees, unauthorized inspection fees and demanded full payment and threatend to start legal procedures of foreclosure. I contacted XXXX representatives in XXXX week trying to resolve this proplem. XXXX did XXXX escrow analysis from XXXX XXXX to XXXX, XXXX and each time my escow shortage changed with each representative. I contacted Bank of America and aske them if they have any knowledge of a missed payment and they said no. I asked Bank of America to fax over my payment history which they did and there was no record of a missed payment. XXXX continued to harrass me as a collection agency does. I was confused about how my mortgage having been serviced by a professional and reputable company such as Bank of America could go from excellent payment history to Foreclosure in a matter of 4 months. I was so distraught I reached out to my brother for support that perhaps I was somehow making a mistake. He looked at my banking records from XXXX XXXX Bank and Bank of America 's record and he too found no missing payments and he wrote the CEO of the Company and filed a complaint that XXXX was falsesifying records to delibertly cause my loan to be in default, however, XXXX 's investigation found no errors and reported my loan deliquent to the credit bureau and I was disqulified from receiving my {$5000.00} inscentive payment for keeping my loan in good standing. After much grief dealing with a Criminal company, I reached out to the XXXX office to file a complaint against XXXX and discovered XXXX is not a bank at all they are a fly by night collection company. Bank of America has no documentation of XXXX ever sending them funds on XXXX XXXX and there is no missing payment. XXXX is running scams on their customers and there is plenty documentatiion as such. My loan should have never went to a collection agency and XXXX uses off shore agents to handle mortgages and unauthorized escrow agents who are not trained and who has made many mistakes on my account. In XXXX, XXXX blessed me to receive the hardest hit fund in the amount of {$20000.00} to be applied to the principal balance but Nationstar didnt apply the funds until XXXX, XXXX. I had made several extra payments to my principal balance but XXXX refused to apply these funds as I alocated .Why was my loan turned over to collection</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was told I could not get modification ok.so I was read on XXXX XXXX XXXX web hardest hit funds programs and XXXX XXXX XXXX home equity assistance or and repayment plans of up to 12 months to help catch up on a past due payments and I was not told about this forbearance I can do that all so I did not no they had all these programs I only no about the modification program I found this on XXXX XXXX XXXX web I do n't need my payment to be reduce i can pay that and all so and extra {$500.00} a month to caught up I 'm out of work because I was XXXX by a lady and she was very XXXX and that why I 'm out of work these last four year I ben having not such good luck first I had XXXX XXXX and I beat that thank to XXXX and now XXXX XXXX XXXX XXXX and both of my XXXX XXXX XXXX XXXX XXXX XXXX XXXX and I have XXXX XXXX XXXX XXXX I did not ask for this. all I 'm ask for to be able to pay a full note and {$500.00} extra thank u</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Date : XX/XX/2021 Amount : {$4500.00} I tried calling the issuer of the XXXX  Unemployment Card ( Bank of America XXXX about why they get my unemployment card closed which they have no positive responds. I tried sending out my unemployment money in the unemployment card to an authorized third party and the Bank of America got my card closed. After several callings and provision of all required information they still can not uplift the lock on my card.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have started refinance process with Bank of America in XX/XX/2017 whereas the sales agent promised me best rates and smooth process. As part of the process, they told me that they will carry out appraisal of my house and I need to pay upfront for it. I was not shared the amount that I need to pay for appraisal and was told that I will be refunded at the end when appraisal closes. I agreed to it as I didn't expect any issues in my loan process. During appraisal, an incorrect report came out which talks about an issue that I don't have in my home. I tried to explain to bank and appraisal company but they are not ready to correct the report resulting in my mortgage process going on hold. Bank has charged me for my appraisal fees but they didn't worked with appraisal company to correct the report even after I provided the reason for incorrectness of the report. My home ( in exactly same condition ) has gone through 3-4 appraisals before this appraisal but never such issue happened. I can provide more specifics when asked. \\n\\nI have also reached out to XXXX, CA to help me with issue in appraisal report.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have been working with XXXX for the past two years to get a home loan with Bank of America. My closing was schedule for XX/XX/XXXX. On XX/XX/XXXX my file to updated and showed, \" XXXX pending compliance and verbal verification of employment. '' Two days later, underwriting was suspended and additional conditions was placed on my file. All additional information was provided and closing was then extended to XX/XX/XXXX. My XXXX counselor and closing attorney has tried with no success since XX/XX/XXXX to contact someone in the underwriting department of BOA and no one is responding. I have already wired my closing funds to the attorney. Due to the explainable delay, I was forced to give up my apartment and place my belongings in storage.My son and I am now living in car just to achieve the American Dream. I have XXXX and my health is being seriously impacted by this as well. Moving my stuff to the storage unit cost me {$820.00}, which means I will be charged another {$820.00} to move my stuff from there. I was told by another agent that works with XXXX that she has clients that were cleared to closed since XX/XX/2019 and Bank of America still has no sent the paperwork to the closing attorney. \\nI would really hope that Bank of America is not intentionally stall the XXXX loans. I just want to close on this house and get on with my life. I am afraid that the seller might terminate the contact and walk away with my earnest money. PLEASE HELP ME!!!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is a \" qualified written request '' under Sec tion 6 of  the Real Estate Settlement Procedures Act ( RESPA ).     I am writing you today as I disagree with the past due payments you are reporting on my credit reports. They do not line up with my records and I believe that my payments  may have  been misapplied. The particular lates referred to are : Late Payments Being Reported : 60 days past due as of  XXXX   XXXX  30 days past due as of  XXXX   XXXX ,  XXXX   XXXX ,  XXXX   XXXX ,  XXXX   XXXX ,  XXXX   XXXX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I am working with Bank of America on a home loan. The closing is scheduled for today ie XXXX XXXX, 2015. But even after repeated requests I was not provided the closing disclosure documents. They just sent it to me and its not what we had discussed initially. They pushed out my closing several times stating they had not received some documents from the closing attorney etc. I dont understand how they can be so lax in their approach. Why cant they track progress and raise a red flag if something is not happening on time..This has caused tremendous discomfort and heartache to my family and me. Pls help..</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating the confusion matrix of the fine-tuned model",
   "id": "7640b083b18837fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T22:17:42.966980Z",
     "start_time": "2025-01-27T22:17:31.600855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "create_confusion_matrix(data = tokenized_dataset[\"test\"],\n",
    "                        cl_classes= product_classes,\n",
    "                        trainer_ = trainer,\n",
    "                        title_text = 'Confusion Matrix (GPT-2 Quantised + Lora) - Validation Set')"
   ],
   "id": "a3d5665409a82154",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loading the fine-tuned peft model and validating on the test data",
   "id": "38a2c100fed8a1c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T20:18:19.481241Z",
     "start_time": "2025-01-29T20:16:58.706681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Loading the model\n",
    "from peft import AutoPeftModelForSequenceClassification\n",
    "path = \"./vtsoumpris/fnc-gpt2-q4lora\"\n",
    "\n",
    "LoRA_model = AutoPeftModelForSequenceClassification.from_pretrained(path)\n",
    "#LoRA_model_2 = prepare_model_for_kbit_training(LoRA_model)"
   ],
   "id": "806f45c7e57a683c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vtsoumpris\\PycharmProjects\\Lightweight_FineTuning_FoundationModel\\venv\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T20:18:19.959739Z",
     "start_time": "2025-01-29T20:18:19.951682Z"
    }
   },
   "cell_type": "code",
   "source": "LoRA_model",
   "id": "91ca20c10a946c35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=2304, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=6, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=6, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=3072, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=6, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=3072)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=6, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=6, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T20:18:20.065666Z",
     "start_time": "2025-01-29T20:18:20.050659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LoRA_model_2 = prepare_model_for_kbit_training(LoRA_model)\n",
    "LoRA_model_2"
   ],
   "id": "f09665b727bf47f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=2304, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=6, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=6, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=3072, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=6, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=3072)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=6, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=6, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T20:24:11.056631Z",
     "start_time": "2025-01-29T20:24:11.046398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# passing the LoRA_model as the new model parameter for the previously created trainer\n",
    "trainer.model = LoRA_model_2\n",
    "trainer.model.to(\"cuda\")\n",
    "# Update the model config with the pad token ID\n",
    "trainer.model.config.pad_token_id = tokenizer.pad_token_id"
   ],
   "id": "d7ad780332a86836",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T20:24:23.016068Z",
     "start_time": "2025-01-29T20:24:12.815666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_ft = trainer.evaluate()\n",
    "results_ft"
   ],
   "id": "5e386544579eac12",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.43644875288009644,\n",
       " 'eval_model_preparation_time': 0.005,\n",
       " 'eval_accuracy': 0.765,\n",
       " 'eval_precision': 0.9206349206349206,\n",
       " 'eval_recall': 0.58,\n",
       " 'eval_f1': 0.7116564417177914,\n",
       " 'eval_runtime': 10.1838,\n",
       " 'eval_samples_per_second': 39.278,\n",
       " 'eval_steps_per_second': 4.91}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Evaluation metrics of the gpt-2 foundation model (non quantized)",
   "id": "836bf2d4a1797dc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T22:25:07.678174Z",
     "start_time": "2025-01-27T22:24:58.911578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "initial_model = \\\n",
    "\tAutoModelForSequenceClassification.from_pretrained(\n",
    "\t\"gpt2\",\n",
    "    num_labels = 2,\n",
    "    id2label={0: \"Mortgage\", 1: \"Credit card or prepaid card\"},\n",
    "    label2id={\"Credit card or prepaid card\": 1, \"Mortgage\": 0}\n",
    ")\n",
    "initial_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Initialize Trainer to use it for evaluation of foundation model\n",
    "initial_trainer = \\\n",
    "Trainer(\n",
    "\tmodel = initial_model,\n",
    "\tdata_collator = DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "\ttokenizer = tokenizer,\n",
    "\teval_dataset = tokenized_dataset[\"test\"],\n",
    "\tcompute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "# using predict() method to validate the model on the tokenized_dataset[\"test\"] dataset\n",
    "val_predictions = initial_trainer.predict(tokenized_dataset[\"test\"])\n",
    "# shape check\n",
    "print(val_predictions.predictions.shape, val_predictions.label_ids.shape)\n",
    "# printing the metrics from prediction\n",
    "val_predictions.metrics"
   ],
   "id": "e4ebdcbc8d9559e6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vtsoumpris\\AppData\\Local\\Temp\\ipykernel_22560\\1980473021.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2) (400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.9144830107688904,\n",
       " 'test_model_preparation_time': 0.002,\n",
       " 'test_accuracy': 0.5025,\n",
       " 'test_precision': 0.6666666666666666,\n",
       " 'test_recall': 0.01,\n",
       " 'test_f1': 0.019704433497536946,\n",
       " 'test_runtime': 7.845,\n",
       " 'test_samples_per_second': 50.988,\n",
       " 'test_steps_per_second': 6.373}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating a dataframe of the models' performance results",
   "id": "4bc08664fdd37cb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T22:25:31.376577Z",
     "start_time": "2025-01-27T22:25:31.363903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results[\"model\"] = [\"gpt2-q4-LoRA\", \"gpt2\"]\n",
    "df_results[\"val_loss\"] = [results_ft[\"eval_loss\"], val_predictions.metrics[\"test_loss\"]]\n",
    "df_results[\"accuracy\"] = [results_ft[\"eval_accuracy\"], val_predictions.metrics[\"test_accuracy\"]]\n",
    "df_results[\"precision\"] = [results_ft[\"eval_precision\"], val_predictions.metrics[\"test_precision\"]]\n",
    "df_results[\"recall\"] = [results_ft[\"eval_recall\"], val_predictions.metrics[\"test_recall\"]]\n",
    "df_results[\"f1\"] = [results_ft[\"eval_f1\"], val_predictions.metrics[\"test_f1\"]]"
   ],
   "id": "d42464443fca2c10",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Saving Results",
   "id": "704e9b8e4a62f1da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T22:25:33.208532Z",
     "start_time": "2025-01-27T22:25:33.197479Z"
    }
   },
   "cell_type": "code",
   "source": "df_results.to_csv(\"./metric_results/res_gpt2_q4_lora.csv\", index=False)",
   "id": "6538c1dfe62b88e7",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Comparing performance results (validation set)",
   "id": "a36f388f0b60a5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T22:25:34.056074Z",
     "start_time": "2025-01-27T22:25:34.045267Z"
    }
   },
   "cell_type": "code",
   "source": "df_results",
   "id": "960cced335a97993",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          model  val_loss  accuracy  precision  recall        f1\n",
       "0  gpt2-q4-LoRA  0.436449    0.7650   0.920635    0.58  0.711656\n",
       "1          gpt2  0.914483    0.5025   0.666667    0.01  0.019704"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2-q4-LoRA</td>\n",
       "      <td>0.436449</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.711656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>0.914483</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.019704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T22:25:46.656524Z",
     "start_time": "2025-01-27T22:25:46.650500Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.cuda.memory_summary(device = None, abbreviated = False))",
   "id": "5a1eb7a39b72292f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   2593 MiB |   3996 MiB | 175138 GiB | 175135 GiB |\n",
      "|       from large pool |   2512 MiB |   3915 MiB | 174773 GiB | 174770 GiB |\n",
      "|       from small pool |     81 MiB |     94 MiB |    365 GiB |    365 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   2593 MiB |   3996 MiB | 175138 GiB | 175135 GiB |\n",
      "|       from large pool |   2512 MiB |   3915 MiB | 174773 GiB | 174770 GiB |\n",
      "|       from small pool |     81 MiB |     94 MiB |    365 GiB |    365 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   2585 MiB |   3989 MiB | 175080 GiB | 175078 GiB |\n",
      "|       from large pool |   2504 MiB |   3907 MiB | 174715 GiB | 174713 GiB |\n",
      "|       from small pool |     81 MiB |     94 MiB |    365 GiB |    365 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   4424 MiB |   4424 MiB |   4444 MiB |  20480 KiB |\n",
      "|       from large pool |   4328 MiB |   4328 MiB |   4348 MiB |  20480 KiB |\n",
      "|       from small pool |     96 MiB |     96 MiB |     96 MiB |      0 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 235684 KiB | 432163 KiB |  53277 GiB |  53277 GiB |\n",
      "|       from large pool | 233472 KiB | 430080 KiB |  52904 GiB |  52904 GiB |\n",
      "|       from small pool |   2212 KiB |   8399 KiB |    372 GiB |    372 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1389    |    1562    |    5463 K  |    5461 K  |\n",
      "|       from large pool |     191    |     241    |    3873 K  |    3873 K  |\n",
      "|       from small pool |    1198    |    1321    |    1589 K  |    1588 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1389    |    1562    |    5463 K  |    5461 K  |\n",
      "|       from large pool |     191    |     241    |    3873 K  |    3873 K  |\n",
      "|       from small pool |    1198    |    1321    |    1589 K  |    1588 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      97    |      97    |      98    |       1    |\n",
      "|       from large pool |      49    |      49    |      50    |       1    |\n",
      "|       from small pool |      48    |      48    |      48    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      29    |      66    |    2075 K  |    2075 K  |\n",
      "|       from large pool |      19    |      30    |    1585 K  |    1585 K  |\n",
      "|       from small pool |      10    |      54    |     489 K  |     489 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T21:05:42.178207Z",
     "start_time": "2025-01-27T21:05:42.174487Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5bf3dd5cafb6755e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

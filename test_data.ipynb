{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a test dataset to use after fine-tuning\n",
    "\n",
    "This notebook focuses on creating a test dataset to evaluate the performance of fine-tuned models on completely unseen data. The process ensures that no overlap exists between the training dataset (`filtered_dataset.csv`) and the newly created test dataset."
   ],
   "id": "713f2328c9d6cc7b"
  },
  {
   "cell_type": "code",
   "id": "e204eaab42fc02f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:38:56.316565Z",
     "start_time": "2025-01-26T14:38:53.924756Z"
    }
   },
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Overlap validator as a function (between datasets)",
   "id": "6f72fe93adef5082"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:38:56.327243Z",
     "start_time": "2025-01-26T14:38:56.321577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Validator to ensure no overlap between test_dataset and filtered_dataset.csv\n",
    "def validate_no_overlap(existing_narratives, new_test_df):\n",
    "\t\"\"\"\n",
    "    Validates that none of the 'Consumer complaint narrative' values in the new test dataset\n",
    "    are present in the existing dataset.\n",
    "\n",
    "    Parameters:\n",
    "        existing_narratives: Set of existing narratives (from `filtered_dataset.csv`).\n",
    "        new_test_df: Pandas DataFrame of the newly created test dataset.\n",
    "\n",
    "    Returns:\n",
    "        Bool: True if no overlap, False otherwise (with print of duplicate entries if found).\n",
    "    \"\"\"\n",
    "\t# Extract narratives from the new test dataset\n",
    "\ttest_narratives = set(new_test_df[\"Consumer complaint narrative\"].dropna().unique())\n",
    "\n",
    "\t# Find intersection\n",
    "\toverlapping_narratives = test_narratives.intersection(existing_narratives)\n",
    "\n",
    "\t# Check if there is any overlap\n",
    "\tif overlapping_narratives:\n",
    "\t\tprint(\"Validation Failed: The following narratives overlap with the existing dataset:\")\n",
    "\t\tfor narrative in overlapping_narratives:\n",
    "\t\t\tprint(f\" - {narrative}\")\n",
    "\t\treturn False\n",
    "\telse:\n",
    "\t\tprint(\"Validation Passed: No overlapping narratives found.\")\n",
    "\t\treturn True\n"
   ],
   "id": "109ca6f429d5eda0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loading the original dataset and applying the same filters",
   "id": "3d08fd43118bc9c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:39:00.510517Z",
     "start_time": "2025-01-26T14:38:56.588878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the original dataset from Hugging Face\n",
    "original_dataset = load_dataset(\"BEE-spoke-data/consumer-finance-complaints\", split = \"train\")\n",
    "\n",
    "# Apply filters to get rows matching the specified criteria\n",
    "filtered_dataset = original_dataset.filter(\n",
    "\tlambda row: row[\"Company\"] == \"BANK OF AMERICA, NATIONAL ASSOCIATION\"\n",
    "\t            and row[\"Product\"] in [\"Credit card or prepaid card\", \"Mortgage\"]\n",
    "\t            and row[\"Consumer complaint narrative\"] is not None\n",
    ")\n",
    "\n",
    "# Load the previously processed dataset from CSV\n",
    "filtered_dataset_csv = pd.read_csv(\"data/filtered_dataset.csv\")"
   ],
   "id": "978d318371484ec3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Excluding the instances that exist in **filtered_dataset**",
   "id": "f49d151c551ef9e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:40:03.353152Z",
     "start_time": "2025-01-26T14:40:02.881539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract narratives from the CSV to use for exclusion\n",
    "existing_narratives = set(filtered_dataset_csv[\"Consumer complaint narrative\"].dropna().unique())\n",
    "\n",
    "# Exclude rows with matching \"Consumer complaint narrative\"\n",
    "remaining_dataset = filtered_dataset.filter(\n",
    "\tlambda row: row[\"Consumer complaint narrative\"] not in existing_narratives\n",
    ")\n",
    "\n",
    "# Separate the remaining dataset into the two product classes\n",
    "mortgage_dataset = remaining_dataset.filter(lambda row: row[\"Product\"] == \"Mortgage\")\n",
    "credit_card_dataset = remaining_dataset.filter(lambda row: row[\"Product\"] == \"Credit card or prepaid card\")\n",
    "\n",
    "# Sample 100 rows from each class (use a fixed seed for consistent test set generation)\n",
    "mortgage_sample = mortgage_dataset.shuffle(seed = 42).select(range(100))\n",
    "credit_card_sample = credit_card_dataset.shuffle(seed = 42).select(range(100))\n",
    "\n",
    "# Combine the two samples into one test dataset\n",
    "test_dataset = concatenate_datasets([mortgage_sample, credit_card_sample])\n",
    "\n",
    "# Keep only the required columns: \"Consumer complaint narrative\" and \"Product\"\n",
    "test_dataset = test_dataset.remove_columns(\n",
    "\t[col for col in remaining_dataset.column_names if col not in [\"Consumer complaint narrative\", \"Product\"]]\n",
    ")"
   ],
   "id": "caf74c6f794009f4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Converting to pandas dataframe, validating and extracting the unseen data in test_dataset.csv",
   "id": "38c83bcafae5ed9a"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-26T14:40:05.692801Z",
     "start_time": "2025-01-26T14:40:05.672363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the dataset to a pandas DataFrame\n",
    "test_df = test_dataset.to_pandas()\n",
    "\n",
    "# Validate the new test dataset\n",
    "validation_result = validate_no_overlap(existing_narratives, test_df)\n",
    "\n",
    "# Save the dataset only if validation passes\n",
    "if validation_result:\n",
    "\t# Define the output folder and file path using pathlib\n",
    "\toutput_folder = Path(\"data\")\n",
    "\toutput_folder.mkdir(exist_ok = True)  # Create the folder if it doesn't exist\n",
    "\ttest_output_path = output_folder / \"test_dataset.csv\"\n",
    "\n",
    "\t# Save the new test dataset to a CSV file for evaluation purposes\n",
    "\ttest_df.to_csv(test_output_path, index = False)\n",
    "\tprint(f\"Test dataset successfully saved to {test_output_path}\")\n",
    "else:\n",
    "\tprint(\"Test dataset not saved due to overlapping entries.\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Passed: No overlapping narratives found.\n",
      "Test dataset successfully saved to data\\test_dataset.csv\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:39:01.022194Z",
     "start_time": "2025-01-26T14:39:01.019707Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "db94b7bd6ac9091c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
